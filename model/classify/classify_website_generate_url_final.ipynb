{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bdd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ee391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = ''\n",
    "content = ''\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e99f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_website_links():\n",
    "    # Finding all the <Meta>, <Script>, and <Link> tags\n",
    "    meta_tags = soup.find_all('meta')\n",
    "    script_tags = soup.find_all('script')\n",
    "    link_tags = soup.find_all('link')\n",
    "\n",
    "    total_links = len(meta_tags) + len(script_tags) + len(link_tags)\n",
    "    return total_links\n",
    "\n",
    "def check_anchor_url():\n",
    "    # Finding all the <a> tags\n",
    "    anchor_tags = soup.find_all('a')\n",
    "    \n",
    "    # Counting the number of anchor tags with different domain names\n",
    "    different_domain_count = 0\n",
    "    for anchor in anchor_tags:\n",
    "        href = anchor.get('href')\n",
    "        if href is not None and not re.match(r'^#|javascript:', href):\n",
    "            if not href.startswith('/') and not href.startswith('http'):\n",
    "                different_domain_count += 1\n",
    "\n",
    "    return different_domain_count\n",
    "\n",
    "def check_request_url():\n",
    "    # Finding all the external objects (images, videos, sounds) in the webpage\n",
    "    objects = soup.find_all(['img', 'video', 'audio'])\n",
    "    \n",
    "    # Counting the total number of external objects\n",
    "    total_objects = len(objects)\n",
    "    if (total_objects == 0) :\n",
    "        return 1\n",
    "    \n",
    "    # Counting the number of external objects with different domains\n",
    "    different_domain_count = 0\n",
    "    for obj in objects:\n",
    "        src = obj.get('src')\n",
    "        if src is not None:\n",
    "            parsed_url = urlparse(src)\n",
    "            if parsed_url.netloc != urlparse(hostname).netloc:\n",
    "                different_domain_count += 1\n",
    "    \n",
    "    # Calculating the percentage of request URLs for external objects\n",
    "    percentage = (different_domain_count / total_objects) * 100\n",
    "    return different_domain_count\n",
    "    # Classifying the webpage based on the percentage of request URLs for external objects\n",
    "    if percentage < 22:\n",
    "        return 1\n",
    "    elif percentage >= 22 and percentage <= 61:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def check_email_submission():\n",
    "    # Checking for the use of \"mail()\" function in PHP\n",
    "    email_submission = soup.find_all(lambda tag: tag.name == 'form' and 'mail(' in tag.get('action', ''))\n",
    "    \n",
    "    # Checking for the use of \"mailto:\" function\n",
    "    mailto_links = soup.find_all('a', href=lambda href: href and href.lower().startswith('mailto:'))\n",
    "    \n",
    "    return len(mailto_links) + len(email_submission)\n",
    "\n",
    "def check_different_href_urls():\n",
    "    # Finding elements with \"onMouseOver\" attributes\n",
    "    elements = soup.find_all(attrs={\"onMouseOver\": True})\n",
    "\n",
    "    count_different_href_urls = 0\n",
    "    for element in elements:\n",
    "        # Finding elements with \"onMouseOver\" and \"onClick\" attributes\n",
    "        href_url = element.get(\"href\")\n",
    "        onclick_href_url = element.get(\"onClick\", \"\").split(\"=\")[-1].strip(\"'\\\";\")\n",
    "        onmouseover_href_url = element.get(\"onMouseOver\", \"\").split(\"=\")[-1].strip(\"'\\\";\")\n",
    "\n",
    "        count_different_href_urls\n",
    "\n",
    "        if href_url:\n",
    "            if onmouseover_href_url != href_url:\n",
    "                count_different_href_urls = count_different_href_urls + 1\n",
    "        elif onclick_href_url:\n",
    "            if onmouseover_href_url != onclick_href_url:\n",
    "                count_different_href_urls = count_different_href_urls + 1\n",
    "\n",
    "    return count_different_href_urls\n",
    "\n",
    "def check_right_click_disabled():\n",
    "    # Searching for the event \"event.button==2\" in the HTML content\n",
    "    if \".button==2\" in content:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def check_popup_window_text_fields():\n",
    "    # Finding the URL of the pop-up window\n",
    "    popup_url = None\n",
    "    count_popup_window_text_fields = 0\n",
    "    for script in soup.find_all('script'):\n",
    "        if 'window.open' in script.text:\n",
    "            popup_url = script.text.split('window.open(')[1].split(',')[0].strip(\"'\")\n",
    "\n",
    "            if popup_url:\n",
    "                # Sending a GET request to the pop-up window URL and retrieving the HTML content\n",
    "                popup_response = requests.get(popup_url)\n",
    "                popup_html_content = popup_response.text\n",
    "\n",
    "                # Parsing the pop-up window HTML content\n",
    "                popup_soup = BeautifulSoup(popup_html_content, 'html.parser')\n",
    "\n",
    "                # Finding input elements in the pop-up window HTML content\n",
    "                input_elements = popup_soup.find_all('input')\n",
    "\n",
    "                for input_element in input_elements:\n",
    "                    input_type = input_element.get('type')\n",
    "                    if input_type == 'text':\n",
    "                        count_popup_window_text_fields = count_popup_window_text_fields + 1\n",
    "\n",
    "    return count_popup_window_text_fields\n",
    "\n",
    "def check_iframe_redirection():\n",
    "    # Finding iframe elements in the HTML content\n",
    "    iframe_elements = soup.find_all('iframe')\n",
    "    print( iframe_elements )\n",
    "\n",
    "    return len(iframe_elements)\n",
    "\n",
    "def check_favicon_external_domain():\n",
    "    # Finding the favicon link element in the HTML content\n",
    "    favicon_link = soup.find('link', rel=['icon', 'shortcut icon'])\n",
    "    count_favicon_link = 0\n",
    "    if favicon_link:\n",
    "        favicon_url = favicon_link.get('href')\n",
    "        parsed_url = urlparse(favicon_url)\n",
    "        domain = parsed_url.netloc\n",
    "\n",
    "        # Checking if the favicon URL domain is different from the URL domain\n",
    "        if hostname not in favicon_link.get('href'):\n",
    "            count_favicon_link = count_favicon_link + 1\n",
    "\n",
    "    return count_favicon_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc0a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv( item ):\n",
    "    with open('./dataset/website_url_test.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # print( f\"item {item}\" )\n",
    "        writer.writerow([\n",
    "            hostname, \n",
    "            item['website_links'],\n",
    "            item['anchor_url'],\n",
    "            item['request_url'],\n",
    "            item['email_submission'],\n",
    "            item['different_href_urls'],\n",
    "            item['right_click_disabled'],\n",
    "            item['popup_window_text_fields'],\n",
    "            item['iframe_redirection'],\n",
    "            item['favicon_external_domain'],\n",
    "            1\n",
    "        ])\n",
    "\n",
    "def start_classify(file_path):\n",
    "    with open(file_path, 'r') as html_file:\n",
    "        content = html_file.read()\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        # print( f\"soup {soup}\" )\n",
    "        results = {}\n",
    "        results['website_links'] = check_website_links()\n",
    "        results['anchor_url'] = check_anchor_url()\n",
    "        results['request_url'] = check_request_url()\n",
    "        results['email_submission'] = check_email_submission()\n",
    "        results['different_href_urls'] = check_different_href_urls()\n",
    "        results['right_click_disabled'] = check_right_click_disabled()\n",
    "        results['popup_window_text_fields'] = check_popup_window_text_fields()\n",
    "        results['iframe_redirection'] = check_iframe_redirection()\n",
    "        results['favicon_external_domain'] = check_favicon_external_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20276954",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = './dataset/website_url.csv'\n",
    "with open(csv_file, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header row\n",
    "\n",
    "    # Loop through each row in the CSV file\n",
    "    for row in reader:\n",
    "        uid = row[0]\n",
    "        url = row[1]\n",
    "        parsed_url = urlparse(url)\n",
    "        hostname = parsed_url.hostname\n",
    "\n",
    "        # Check if the URL matches a file in the demo folder\n",
    "        file_name = os.path.basename(uid+'.html')\n",
    "        file_path = os.path.join('./web_content', file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            start_classify(file_path)\n",
    "            print( f\"file_name {file_name}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458cf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
